{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile read_and_load.py\n",
    "\n",
    "from openvino.inference_engine import IENetwork, IECore\n",
    "\n",
    "import cv2\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "class read_and_load:\n",
    "    \n",
    "    '''\n",
    "    Class for reading and loading the model\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, model_name, model_path, device, extensions=None):\n",
    "        \n",
    "        self.model_weights = model_path+'.bin'\n",
    "        self.model_structure = model_path+'.xml'\n",
    "        self.device = device\n",
    "        self.model_name = model_name\n",
    "       \n",
    "\n",
    "    def load_model(self): \n",
    "        \n",
    "        try:\n",
    "            self.model = IENetwork(self.model_structure,self.model_weights)\n",
    "        except Exception as e:\n",
    "            logging.error(f'{e}: check the path of the input model')\n",
    "\n",
    "        \n",
    "        self.input_name=next(iter(self.model.inputs))\n",
    "        self.input_shape=self.model.inputs[self.input_name].shape\n",
    "        self.output_name=next(iter(self.model.outputs))\n",
    "        self.output_shape=self.model.outputs[self.output_name].shape\n",
    "        \n",
    "        core = IECore()\n",
    "        self.network = core.load_network(network=self.model,device_name=self.device, num_requests=1)\n",
    "        logging.info(f'{self.model_name} model loaded successfully')\n",
    "       \n",
    "        \n",
    "    def preprocess_input(self, image):\n",
    "        input_image = cv2.resize(image, (self.input_shape[3], self.input_shape[2]))\n",
    "        input_image = input_image.transpose((2, 0, 1))\n",
    "        input_image = input_image.reshape(1, *input_image.shape)\n",
    "        #logging.info(f'{self.model_name} preprocessing of input completed')\n",
    "        return {self.input_name: input_image}\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile face_detect.py\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "#from openvino.inference_engine import IENetwork, IECore\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "from read_and_load import read_and_load\n",
    "\n",
    "class face_detect(read_and_load):\n",
    "    '''\n",
    "    Class for the Face Detection Model.\n",
    "    '''\n",
    "\n",
    "    def predict(self, image_inp):\n",
    "      \n",
    "        net_input = self.preprocess_input(image_inp)\n",
    "        infer_request_handle = self.network.start_async(request_id=0, inputs=net_input)\n",
    "        if infer_request_handle.wait() == 0:\n",
    "            net_output = infer_request_handle.outputs[self.output_name]\n",
    "            #print(np.shape(net_output))\n",
    "            boxes = self.preprocess_output(net_output)\n",
    "        return self.draw_outputs(boxes, image_inp)\n",
    "\n",
    "\n",
    "        \n",
    "    def draw_outputs(self, coords, image):\n",
    " \n",
    "        w = image.shape[1]\n",
    "        h = image.shape[0]\n",
    "        boxes = []\n",
    "        for box in coords:\n",
    "            p1 = (int(box[0] * w), int(box[1] * h))\n",
    "            p2 = (int(box[2] * w), int(box[3] * h))\n",
    "            boxes.append([p1[0], p1[1], p2[0], p2[1]])\n",
    "            image = cv2.rectangle(image, p1, p2, (0, 0, 255), 3)\n",
    "            crp_img = image[p1[1]:p2[1],p1[0]:p2[0]]\n",
    "        return boxes,image,crp_img\n",
    "\n",
    "    def preprocess_output(self, outputs):\n",
    "        self.threshold = 0.5\n",
    "        boxes = []\n",
    "        probs = outputs[0, 0, :, 2]\n",
    "        for i, p in enumerate(probs):\n",
    "            if p > self.threshold:\n",
    "                box = outputs[0, 0, i, 3:]\n",
    "                boxes.append(box)\n",
    "        return boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile landmark.py\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from read_and_load import read_and_load\n",
    "#from openvino.inference_engine import IENetwork, IECore\n",
    "\n",
    "\n",
    "class landmark(read_and_load):\n",
    "    \n",
    "    def predict(self, image):\n",
    "        self.img = image\n",
    "        net_input = self.preprocess_input(self.img)\n",
    "        infer_request_handle = self.network.start_async(request_id=0, inputs=net_input)\n",
    "        if infer_request_handle.wait() == 0:\n",
    "            self.net_output = infer_request_handle.outputs[self.output_name]\n",
    "            self.x,self.y = self.find_points()\n",
    "            right_eye,left_eye = self.crop_eyes(self.x,self.y)\n",
    "            \n",
    "            img_circle = self.draw_circle()\n",
    "            return(img_circle,right_eye,left_eye,self.x,self.y)\n",
    "           \n",
    "    \n",
    "    def find_points(self):\n",
    "        h,w,_ = np.shape(self.img)\n",
    "        x=[]\n",
    "        y=[]\n",
    "        for i,j in enumerate(np.squeeze(self.net_output)):\n",
    "            if (i+1)%2 == 0:\n",
    "                y.append(int(j*h))\n",
    "            else:\n",
    "                x.append(int(j*w))\n",
    "        return(x,y)\n",
    "    \n",
    "    def draw_circle(self):\n",
    "        for i in range(2):\n",
    "            cv2.rectangle(self.img,(self.x[i]-30,self.y[i]-30),(self.x[i]+30,self.y[i]+30),(255,0,0),1)\n",
    "        return(self.img) \n",
    "    \n",
    "    def crop_eyes(self,x,y):\n",
    "        right_eye = self.img[y[0]-15:y[0]+15,x[0]-15:x[0]+15]\n",
    "        left_eye = self.img[y[1]-15:y[1]+15,x[1]-15:x[1]+15]\n",
    "        return(right_eye,left_eye)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile head_pose.py\n",
    "\n",
    "from read_and_load import read_and_load\n",
    "from openvino.inference_engine import IENetwork, IECore\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "class head_pose(read_and_load):\n",
    "    \n",
    "    def load_model(self): \n",
    "\n",
    "        self.model = IENetwork(self.model_structure,self.model_weights)\n",
    "        self.input_name=next(iter(self.model.inputs))\n",
    "        self.input_shape=self.model.inputs[self.input_name].shape\n",
    "        self.output_name=self.model.outputs.keys()\n",
    "        self.output = [i for i in self.output_name]\n",
    "        core = IECore()\n",
    "        self.network = core.load_network(network=self.model,device_name=self.device, num_requests=1)\n",
    "        logging.info('Head pose model loaded successfully')\n",
    "    \n",
    "    def predict(self, image):\n",
    "        self.img = image\n",
    "        net_input = self.preprocess_input(self.img)\n",
    "        infer_request_handle = self.network.start_async(request_id=0, inputs=net_input)\n",
    "        if infer_request_handle.wait() == 0:\n",
    "            self.net_output = [infer_request_handle.outputs[i] for i in self.output]\n",
    "        return(self.net_output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile gaze.py\n",
    "\n",
    "import logging\n",
    "from read_and_load import read_and_load\n",
    "from openvino.inference_engine import IENetwork, IECore\n",
    "import cv2\n",
    "\n",
    "class gaze(read_and_load):\n",
    "    \n",
    "    def load_model(self): \n",
    "        self.input_shapes=[]\n",
    "        self.model = IENetwork(self.model_structure,self.model_weights)\n",
    "        self.input_names=[i for i in iter(self.model.inputs)]\n",
    "        for i in self.input_names:\n",
    "            self.input_shapes.append(self.model.inputs[i].shape)\n",
    "            \n",
    "        self.output_name = next(iter(self.model.outputs))\n",
    "      \n",
    "        core = IECore()\n",
    "        self.network = core.load_network(network=self.model,device_name=self.device, num_requests=1)\n",
    "        #logging.info('Gaze model loaded successfully')\n",
    "        \n",
    "        \n",
    "    def preprocess_input(self, left_eye_image,right_eye_image,head_pose_angles):\n",
    "        #print(np.shape(left_eye_image))\n",
    "        left_eye_image = cv2.resize(left_eye_image, (self.input_shapes[1][3], self.input_shapes[1][2]))\n",
    "        right_eye_image = cv2.resize(right_eye_image, (self.input_shapes[1][3], self.input_shapes[1][2]))\n",
    "        \n",
    "        left_eye_image = left_eye_image.transpose((2, 0, 1))\n",
    "        right_eye_image = right_eye_image.transpose((2, 0, 1))\n",
    "        \n",
    "        left_eye_image = left_eye_image.reshape(1, *left_eye_image.shape)\n",
    "        right_eye_image = right_eye_image.reshape(1, *right_eye_image.shape)\n",
    "        #logging.info(f'{self.model_name} preprocessing input completed')\n",
    "        return {self.input_names[0]:head_pose_angles,self.input_names[1]:left_eye_image,self.input_names[2]:right_eye_image}\n",
    "        \n",
    "    \n",
    "    def predict(self, left_eye_image,right_eye_image,head_pose_angles):\n",
    "        #self.img = image\n",
    "        net_input = self.preprocess_input(left_eye_image,right_eye_image,head_pose_angles)\n",
    "        infer_request_handle = self.network.start_async(request_id=0, inputs=net_input)\n",
    "        if infer_request_handle.wait() == 0:\n",
    "            self.net_output = infer_request_handle.outputs[self.output_name]\n",
    "        return(self.net_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference.py\n",
    "\n",
    "import cv2\n",
    "import logging\n",
    "import numpy as np\n",
    "import argparse\n",
    "from face_detect import face_detect\n",
    "from head_pose import head_pose\n",
    "from landmark import landmark\n",
    "from gaze import gaze\n",
    "from openvino.inference_engine import IENetwork, IECore\n",
    "from movemouse import MouseController\n",
    "\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "def main(args):\n",
    "    \n",
    "        path_fd = args.face_path\n",
    "        fd = face_detect('face detection',path_fd,args.device)\n",
    "        fd.load_model()\n",
    "\n",
    "        path_ld = args.landmark_path\n",
    "        ld = landmark('landmark',path_ld,args.device)\n",
    "        ld.load_model()\n",
    "\n",
    "        path_hdps = args.headpose_path\n",
    "        hp = head_pose('head pose',path_hdps,args.device)\n",
    "        hp.load_model()\n",
    "\n",
    "        gaze_path = args.gaze_path\n",
    "        gz = gaze('Gaze',gaze_path,args.device)\n",
    "        gz.load_model()\n",
    "\n",
    "        if args.input_type == 'video':\n",
    "            cap = cv2.VideoCapture('demo.mp4')\n",
    "        elif args.input_type == 'cam':\n",
    "            cap = cv2.VideoCapture(0)\n",
    "            \n",
    "        video_writer = cv2.VideoWriter('output1.mp4',cv2.VideoWriter_fourcc(*'mp4v'),10,(1920,1080))\n",
    "\n",
    "\n",
    "        if not cap.isOpened():\n",
    "            logging.error('Video file not found. Check the path')\n",
    "\n",
    "\n",
    "        while(cap.isOpened()):\n",
    "            ret,frame = cap.read()\n",
    "            if ret == True:\n",
    "                #img = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "                boxes,pre_img,crp_img = fd.predict(frame)\n",
    "                keypoint_image,right_eye,left_eye,x_e,y_e = ld.predict(crp_img)\n",
    "                hp_vector = hp.predict(crp_img)\n",
    "                hp_vector = np.reshape(hp_vector,(1,3))\n",
    "                mouse_points = gz.predict(left_eye,right_eye,hp_vector)\n",
    "\n",
    "                # rotation vector\n",
    "                rvec = np.array([0, 0, 0], np.float)\n",
    "                # translation vector\n",
    "                tvec = np.array([0, 0, 0], np.float)\n",
    "                # camera matrix\n",
    "                camera_matrix = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]], np.float)\n",
    "\n",
    "                result, _ = cv2.projectPoints(mouse_points, rvec, tvec, camera_matrix, None)\n",
    "                result = result[0][0]\n",
    "\n",
    "                res = (int(result[0] * 100), int(result[1] * 100))\n",
    "                e1 = (boxes[0][0]+x_e[0],boxes[0][1]+y_e[0])\n",
    "                e2 = (boxes[0][0]+x_e[1],boxes[0][1]+y_e[1])\n",
    "\n",
    "\n",
    "                cv2.arrowedLine(pre_img, e1, (e1[0] - res[0], e1[1] + res[1]), (0, 255, 0), 2)\n",
    "                cv2.arrowedLine(pre_img, e2, (e2[0] - res[0], e2[1] + res[1]), (0, 255, 0), 2)\n",
    "                \n",
    "                #move_mouse = MouseController('medium','medium')\n",
    "                #move_mouse.move((e1[0] - res[0], e1[1] + res[1]))\n",
    "\n",
    "                if (args.inter_viz):\n",
    "                    cv2.imshow('frame',pre_img)\n",
    "                    video_writer.write(frame)\n",
    "                    cv2.waitKey(1)\n",
    "            else:\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "     \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--input_type',default=None,\n",
    "                   help = 'Enter \\'video\\' or \\'image\\' or \\'cam\\'')\n",
    "    parser.add_argument('--face_path',default=None,\n",
    "                   help = 'Enter the path for face detection model')\n",
    "    parser.add_argument('--headpose_path',default=None,\n",
    "                   help = 'Enter the path for head pose detection model')\n",
    "    parser.add_argument('--landmark_path',default=None,\n",
    "                   help = 'Enter the path for landmark detection model')\n",
    "    parser.add_argument('--gaze_path',default=None,\n",
    "                   help = 'Enter the path for gaze estimation model')\n",
    "    parser.add_argument('--device',default='CPU',\n",
    "                   help = 'Enter the device to run model')\n",
    "    parser.add_argument('--inter_viz',action = 'store_true',\n",
    "                   help = 'Flag for visualization')\n",
    "\n",
    "    args=parser.parse_args()\n",
    "    main(args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:face detection model loaded successfully\n",
      "INFO:root:landmark model loaded successfully\n",
      "INFO:root:Head pose model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "!python inference.py --input_type video --face_path ./intel/face-detection-adas-binary-0001/FP32-INT1/face-detection-adas-binary-0001 --landmark_path ./intel/landmarks-regression-retail-0009/FP16/landmarks-regression-retail-0009 --headpose_path ./intel/head-pose-estimation-adas-0001/FP16/head-pose-estimation-adas-0001 --gaze_path ./intel/gaze-estimation-adas-0002/FP16/gaze-estimation-adas-0002 --device CPU --inter_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting movemouse.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile movemouse.py\n",
    "\n",
    "import pyautogui\n",
    "import argparse\n",
    "\n",
    "class MouseController:\n",
    "    def __init__(self, precision, speed):\n",
    "        precision_dict={'high':100, 'low':1000, 'medium':500}\n",
    "        speed_dict={'fast':1, 'slow':10, 'medium':5}\n",
    "\n",
    "        self.precision=precision_dict[precision]\n",
    "        self.speed=speed_dict[speed]\n",
    "\n",
    "    def move(self, position):\n",
    "        #print(position)\n",
    "        x,y=position\n",
    "        #print(x*2,y*2)\n",
    "        #pyautogui.moveRel(x*self.precision, -1*y*self.precision, duration=self.speed)\n",
    "        pyautogui.moveTo(x,y,self.speed)\n",
    "        pyautogui.doubleClick()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
